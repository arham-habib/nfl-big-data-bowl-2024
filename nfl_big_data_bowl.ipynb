{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.collections import PatchCollection\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from scipy.spatial import Voronoi, cKDTree\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "\n",
    "# imports from the utils.py script\n",
    "import utils as NFLUtils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_game_data(tracking_file_path: str, plays_file_path: str, game_id: int, chunk_size:int = 10000)->pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load rows from a CSV file that match a specific gameID\n",
    "\n",
    "    Args:\n",
    "    file_path (str): Path to the CSV file\n",
    "    game_id (int): the gameID to filter by\n",
    "    chunk_size (int, optional): the number of rows per chunk, default 10000\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: a DataFrame containing rows with the specified gameID\n",
    "    \"\"\"\n",
    "    data = pd.DataFrame()\n",
    "    # stream data in chunks\n",
    "    for chunk in pd.read_csv(tracking_file_path, chunksize=chunk_size):\n",
    "        filtered_chunk = chunk[chunk['gameId'] == game_id]\n",
    "        # when no more matches, don't parse the rest of the file\n",
    "        if filtered_chunk.shape[0] == 0:\n",
    "            break\n",
    "        data = pd.concat([data, filtered_chunk], ignore_index=True)\n",
    "    plays_df = pd.read_csv(plays_file_path)\n",
    "    data = pd.merge(data, plays_df[['gameId', 'playId', 'possessionTeam', 'ballCarrierId']], on=['gameId', 'playId'])\n",
    "    data = data.loc[data['club'] != 'football']\n",
    "    data['is_offense'] = (data['possessionTeam'] == data['club'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def organize_game_data(df: pd.DataFrame)->dict:\n",
    "    \"\"\"\n",
    "    Organize game data into a nested dictionary structure.\n",
    "\n",
    "    Args:\n",
    "    df (pd.DataFrame): The DataFrame containing game data.\n",
    "\n",
    "    Returns:\n",
    "    dict: A nested dictionary with plays as keys and dictionaries of data where the key is the frame and the values are data from that frame\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize the main dictionary\n",
    "    game_dict = {}\n",
    "\n",
    "    # Iterate over each unique play in the DataFrame\n",
    "    for play_id in df['playId'].unique():\n",
    "\n",
    "        play_df = df[df['playId'] == play_id]\n",
    "        play_events = play_df['event'].unique()\n",
    "\n",
    "\n",
    "        #for now, ignoring fumbles, but maybe later on we can count that as a tackle?\n",
    "        if 'fumble' in play_events:\n",
    "          continue\n",
    "        \n",
    "        play_df = play_df.copy()\n",
    "        if play_df['playDirection'].iloc[0] == 'left':\n",
    "          play_df['x'] = 120 - play_df['x']\n",
    "          play_df['y'] = 53.3 - play_df['y']\n",
    "\n",
    "\n",
    "        # Initialize the play's dictionary\n",
    "        play_dict = {}\n",
    "\n",
    "        start_frame = 1\n",
    "        #another potentiall type of event to include is 'run', but for now i'm excluding that\n",
    "        #because I'm not exactly sure what it means\n",
    "        if 'pass_outcome_caught' in play_events:\n",
    "          start_frame = play_df.loc[play_df['event'] == 'pass_outcome_caught']['frameId'].min()\n",
    "        elif 'handoff' in play_events:\n",
    "          start_frame = play_df.loc[play_df['event'] == 'handoff']['frameId'].min()\n",
    "        else:\n",
    "          continue\n",
    "\n",
    "        #this limits us to plays where a tackle is made\n",
    "        #not sure if we need special consideration for when a runner scores, so those plays are ignored for now\n",
    "        #potentially could include 'out_of_bounds' and factor that into defensive play as well\n",
    "        end_frame = 1\n",
    "        if 'tackle' in play_events:\n",
    "          end_frame = play_df.loc[play_df['event'] == 'tackle']['frameId'].min()\n",
    "        else:\n",
    "          continue\n",
    "\n",
    "        # Iterate over each player in the play\n",
    "        for frame_id in play_df['frameId'].unique():\n",
    "            if (frame_id < start_frame) or (frame_id > end_frame):\n",
    "              continue\n",
    "            frame_df = play_df[play_df['frameId'] == frame_id]\n",
    "\n",
    "            # Select and sort relevant columns\n",
    "            columns = ['nflId', 'time', 'playDirection', 'x', 'y', 's', 'a', 'dis', 'o', 'dir', 'event', 'is_offense', 'ballCarrierId']\n",
    "            frame_df = frame_df[columns]\n",
    "            frame_df = frame_df.astype({'nflId': int, 'ballCarrierId': int})\n",
    "            \n",
    "            # Add the player's DataFrame to the play's dictionary\n",
    "            play_dict[frame_id] = frame_df\n",
    "\n",
    "        # Add the play's dictionary to the main dictionary\n",
    "        game_dict[play_id] = play_dict\n",
    "\n",
    "    return game_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_color_map(nfl_ids):\n",
    "    \"\"\"\n",
    "    Generates a color map for given NFL IDs.\n",
    "\n",
    "    Parameters:\n",
    "    - nfl_ids: List of unique NFL IDs.\n",
    "\n",
    "    Returns:\n",
    "    - Dictionary mapping each NFL ID to a color.\n",
    "    \"\"\"\n",
    "    nfl_ids = nfl_ids.dropna().unique()\n",
    "    colors = plt.cm.rainbow(np.linspace(0, 1, len(nfl_ids)))\n",
    "    color_map = {nfl_id: color for nfl_id, color in zip(nfl_ids, colors)}\n",
    "    return color_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_squares_to_players_OLD(frame_data, x_min=0, x_max=120, y_min=0, y_max=53.3):\n",
    "    # TODO: MADE THIS PRETTY SLOW. We can cache the results of the find_closest_player function embedded to make this faster down the line\n",
    "    \"\"\"\n",
    "    DEPRACATED. UPDATE METHOD BELOW\n",
    "    Assigns each 1-yard square of a football field to the nearest player.\n",
    "\n",
    "    Parameters:\n",
    "    - frame_data (pd.DataFrame): DataFrame with columns ['nflId', 'x', 'y'] representing players' positions.\n",
    "    - x_min, x_max (float): Optional. The minimum and maximum x-coordinates (in yards) of the field area to consider.(0-120 yards)\n",
    "    - y_min, y_max (float): Optional. The minimum and maximum y-coordinates (in yards) of the field area to consider.(0-53.3 yards)\n",
    "\n",
    "    Returns:\n",
    "    - A DataFrame with columns ['square_x', 'square_y', 'closest_player_id'].\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate all 1-yard squares within specified limits\n",
    "    x_range = np.arange(x_min, x_max + 1, 1)\n",
    "    y_range = np.arange(y_min, y_max + 1, 1)\n",
    "    squares = pd.DataFrame([(x, y) for x in x_range for y in y_range], columns=['square_x', 'square_y'])\n",
    "\n",
    "    # Function to find the closest player for a given square\n",
    "    def find_closest_player(square_x, square_y):\n",
    "        frame_data['distance'] = np.sqrt((frame_data['x'] - square_x) ** 2 + (frame_data['y'] - square_y) ** 2)\n",
    "        return frame_data.loc[frame_data['distance'].idxmin()]['nflId']\n",
    "\n",
    "    # Assign each square to the closest player\n",
    "    squares['closest_player_id'] = squares.apply(lambda row: find_closest_player(row['square_x'], row['square_y']), axis=1)\n",
    "\n",
    "    # Drop the temporary distance column from frame_data\n",
    "    frame_data.drop(columns=['distance'], inplace=True)\n",
    "\n",
    "    return squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_field(player_assignments, color_map, min_x=0, max_x=120, min_y=0, max_y=53.3):\n",
    "    \"\"\"\n",
    "    DEPRACATED, I'm creating animations with the create_animation method instead\n",
    "    Visualizes the football field with each 1-yard square colored based on the nearest player.\n",
    "    Squares with no assigned player are left blank (or can be assigned a default color).\n",
    "\n",
    "    Parameters:\n",
    "    - player_assignments (pd.DataFrame): DataFrame with columns ['square_x', 'square_y', 'closest_player_id'].\n",
    "    - color_map (dict): maps each NFL ID to a color, get this using the generate_color_map method\n",
    "    - min_x (float): the min x value in the graph (long side of football field, 0-120)\n",
    "    - max_x (float): the max x\n",
    "    - min_y (float): the min y value in the graph (short axis of football field, 0-53.3)\n",
    "    - max_y (float): the max y\n",
    "    \n",
    "    Return: \n",
    "    - fig\n",
    "    - ax\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Create a figure and axis for the plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    setup_time = time.time()\n",
    "    print(\"Setup Time: \", setup_time - start_time)\n",
    "\n",
    "    # Set up the field dimensions\n",
    "    ax.set_xlim(min_x, max_x)\n",
    "    ax.set_ylim(min_y, max_y)\n",
    "    \n",
    "    set_dimensions_time = time.time()\n",
    "    print(\"Set Dimensions Time: \", set_dimensions_time - setup_time)\n",
    "\n",
    "    # Create a list to hold all the rectangles\n",
    "    rectangles = []\n",
    "\n",
    "    # Create a list to hold the colors of each rectangle\n",
    "    rectangle_colors = []\n",
    "\n",
    "    for _, row in player_assignments.iterrows():\n",
    "        player_id = row['closest_player_id']\n",
    "        square_color = color_map.get(player_id, 'grey')\n",
    "        rect = patches.Rectangle((row['square_x'] - 0.5, row['square_y'] - 0.5), 1, 1)\n",
    "        rectangles.append(rect)\n",
    "        rectangle_colors.append(square_color)\n",
    "\n",
    "    # Create a PatchCollection and add it to the axis\n",
    "    pc = PatchCollection(rectangles, facecolor=rectangle_colors, edgecolor=None)\n",
    "    ax.add_collection(pc)\n",
    "\n",
    "    plotting_time = time.time()\n",
    "    print(\"Plotting Time: \", plotting_time - set_dimensions_time)\n",
    "\n",
    "    # Additional plot settings\n",
    "    ax.set_xlabel('Yards (X-axis)')\n",
    "    ax.set_ylabel('Yards (Y-axis)')\n",
    "    ax.set_title('Bucketed Voronoi')\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(\"Total Execution Time: \", end_time - start_time)\n",
    "\n",
    "    plt.show()\n",
    "    return fig, ax\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_squares_to_players(frame_data, x_min=0, x_max=120, y_min=0, y_max=53.3, x_step=1, y_step=1):\n",
    "    \"\"\"\n",
    "    Assigns each x_step by y_step square of a football field to the nearest player using Voronoi tessellation.\n",
    "\n",
    "    Parameters:\n",
    "    - frame_data (pd.DataFrame): DataFrame with columns ['nflId', 'x', 'y'] representing players' positions.\n",
    "    - x_min, x_max (float): Optional. The minimum and maximum x-coordinates (in yards) of the field area to consider.(0-120 yards)\n",
    "    - y_min, y_max (float): Optional. The minimum and maximum y-coordinates (in yards) of the field area to consider.(0-53.3 yards)\n",
    "    - x_step, y_step (float): Optional. The size of each Voronoi bucket, defaults to 1 yd by 1 yd\n",
    "\n",
    "    Returns:\n",
    "    - A DataFrame with columns ['square_x', 'square_y', 'closest_player_id', 'ball_carrier', 'is_offense'].\n",
    "    \"\"\"\n",
    "    # modify the frame_data such that ever offensive player gets the ballCarrierId (assume they share voronoi space)\n",
    "    # commenting this out for the moment because it wasn't helping the analysis, but in the future, make it such that if they're touching the space of another offensive player they become one unit\n",
    "    ball_carrier = frame_data.ballCarrierId.iloc[0]\n",
    "    # frame_data.loc[frame_data.is_offense == True, 'nflId'] = ball_carrier\n",
    "\n",
    "    # Generate Voronoi diagram\n",
    "    points = frame_data[['x', 'y']].values\n",
    "    vor = Voronoi(points)\n",
    "    # fig = voronoi_plot_2d(vor)\n",
    "    # plt.show()  # for debug purposes \n",
    "\n",
    "    # Generate all 1-yard squares within specified limits\n",
    "    x_range = np.arange(x_min, x_max + x_step, x_step)\n",
    "    y_range = np.arange(y_min, y_max + y_step, y_step)\n",
    "    squares = pd.DataFrame([(x, y) for x in x_range for y in y_range], columns=['square_x', 'square_y'])\n",
    "\n",
    "    # Create a KDTree for efficient nearest neighbor search\n",
    "    tree = cKDTree(points)\n",
    "\n",
    "    # Assign each square to the closest player based on Voronoi regions\n",
    "    squares['closest_player_id'] = squares.apply(lambda row: frame_data.iloc[tree.query((row['square_x'], row['square_y']))[1]]['nflId'], axis=1)\n",
    "    # get the ID of the ball carrier\n",
    "    squares['ball_carrier'] = ball_carrier\n",
    "\n",
    "    return squares\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voronoi_area(squares: pd.DataFrame, weights: pd.DataFrame=None):\n",
    "    \"\"\"\n",
    "    Return the area attributed to each unique player by nflID\n",
    "\n",
    "    Params: \n",
    "    - squares (pd.DataFrame): a dataframe with columns ['square_x', 'square_y', 'closest_player_id'].\n",
    "    - weights (pd.DataFrame): \n",
    "\n",
    "    Returns: \n",
    "    - a dictionary with keys of closest_player_id and values of the voronoi areas, in square yards (we can modify this later with the weights)\n",
    "    \"\"\"\n",
    "    # this is the case where we weight each Voronoi bin differently -- we can implement this later\n",
    "    if weights: \n",
    "        return \n",
    "    else:\n",
    "        voronoi_areas = squares.groupby('closest_player_id').size().to_dict()\n",
    "    \n",
    "    return voronoi_areas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tackle_percentage_contribution_per_frame(frame_data:pd.DataFrame, weights: pd.DataFrame=None, x_step: int=1, y_step: int=1)->dict:\n",
    "    \"\"\" \n",
    "    For every unique player attributed to a square on the defending team, take them out and see how much Voronoi area would be gained by the player in possession. \n",
    "\n",
    "    Params: \n",
    "    - frame_data (pd.DataFrame): a dataframe from the organize_game_data method with columns ['nflId', 'ballCarrierId', 'is_offense', 'x', 'y']\n",
    "    - weights (pd.DataFrame): \n",
    "    - x_step (int): the x-side of the voronoi bins when caling the assign_squres_to_players method\n",
    "    - y_step (int): the y-side of the voronoi bins when caling the assign_squres_to_players method\n",
    "\n",
    "    Returns: \n",
    "    - dictionary with keys of nflId and value of the tackle percentage contribution for that frame\n",
    "    \"\"\"\n",
    "\n",
    "    # if there is a valid set of weights [FINISH THIS]\n",
    "    if weights: \n",
    "        return\n",
    "    \n",
    "    else: \n",
    "        area_protected = {}\n",
    "        # get the ball carrier and offensive players\n",
    "        ball_carrier = frame_data.ballCarrierId.iloc[0]\n",
    "        offensive_players = dict(zip(frame_data.nflId, frame_data.is_offense))\n",
    "\n",
    "        # get the minimum x, after which we will cut off voronoi analysis\n",
    "        x_min = max(10, frame_data.loc[frame_data.nflId==ball_carrier, 'x'].iloc[0] - 10) # we end the voronoi tesselation 10 yards behind the ball carrier or 10, whichever is greater\n",
    "        squares = assign_squares_to_players(frame_data, x_min=x_min, x_step=x_step, y_step=y_step)\n",
    "        baseline_area = voronoi_area(squares)[ball_carrier]\n",
    "        \n",
    "        for player_id in squares.closest_player_id.unique(): \n",
    "            # break for the ball_carrier\n",
    "            if offensive_players[player_id]: \n",
    "                continue\n",
    "            # take the frame data if that player didn't exist\n",
    "            filtered_frame_data = frame_data[frame_data.nflId != player_id]\n",
    "            # calculate how much additional space the offense gets\n",
    "            voronoi_filtered = assign_squares_to_players(filtered_frame_data, x_min=x_min, x_step=x_step, y_step=y_step)\n",
    "            protected_areas = voronoi_area(voronoi_filtered)[ball_carrier]\n",
    "            area_protected[player_id] = protected_areas - baseline_area  # how much more area do they get?\n",
    "    \n",
    "    # divide by the total sum of the frame to get tackle percentage contribution in each frame\n",
    "    # I'm unconvinced this is the correct approach and I'm commenting out out for now, we can talk about this\n",
    "    # Basically, if no one is close to the player on offense, I think this will be misleading\n",
    "    # total_protected_area = sum(area_protected.values())\n",
    "    # for key, value in area_protected.items(): \n",
    "    #     area_protected[key] = value / total_protected_area\n",
    "\n",
    "    return area_protected\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance_per_frame(frame_data:pd.DataFrame)->dict: \n",
    "    \"\"\" \n",
    "    Params: \n",
    "    - frame_data (pd.DataFrame): a dataframe from the organize_game_data method with columns ['nflId', 'ballCarrierId', 'is_offense', 'x', 'y']\n",
    "    Returns: \n",
    "    - distance_dict (dict): a dict where the keys are the player IDs and the values are the distances\n",
    "    \"\"\"\n",
    "    ball_carrier = frame_data.ballCarrierId.iloc[0]\n",
    "    x, y = zip(frame_data.loc[ball_carrier, ['x', 'y']])\n",
    "    defense = frame_data[~frame_data.isOffense].nflId\n",
    "    distances = [sqrt((x-x_d)**2 + (y-y_d)**2) for x_d, y_d in frame_data[~frame_data.isOffense].x, frame_data[~frame_data.isOffense].y]\n",
    "    distance_dict = dict(zip(defense, distances))\n",
    "\n",
    "    return distance_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance_per_play(frame_dict:dict, filepath:str)->dict: \n",
    "    \"\"\" \n",
    "    Calculate the Euclidean distances of each of the defenders from the ball\n",
    "    Params: \n",
    "    - frame_dict: dict from the organize_game_data method for each play\n",
    "    - filepath: the path of each play, under which we can cache the data\n",
    "    \"\"\"\n",
    "    frame_distances = {}\n",
    "    # sort the frames\n",
    "    frame_dict_sorted = sorted(frame_dict.items(), key=lambda x: x[0])\n",
    "    # iterate through the frames of the play\n",
    "    for key, frame in frame_dict_sorted: \n",
    "        frame_distances[key] = euclidean_distance_per_frame(frame)\n",
    "\n",
    "    # Convert the dictionary with the frame data to a DataFrame to cache\n",
    "    # The keys of the outer dict become the index, and the inner dicts' keys become the column names\n",
    "    frame_distances_df = pd.DataFrame.from_dict(frame_distances, orient='index')\n",
    "\n",
    "    # Save to CSV, with the index to make future multiplication easier\n",
    "    frame_distances_df.to_csv(f'{filepath}/distances_per_frame.csv', index=True)\n",
    "    \n",
    "    return frame_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_game_distances(game_id, tracking_file, plays_file='./data/plays.csv', game_file='./data/games.csv')->None:\n",
    "    \"\"\" \n",
    "    A method to cache the distances of the players from the ball at all times\n",
    "    Param: \n",
    "    - game_id (int): the ID of the game as found in the Kaggle cleaned data\n",
    "    - tracking_file (str): the address of the file in which the tracking data is stored\n",
    "    - plays_file (str): the address of the plays file\n",
    "    - game_file (str): the filepath of the file containing information about each game\n",
    "    \"\"\"\n",
    "    \n",
    "    games = pd.read_csv(game_file)\n",
    "    game_data = games[games.gameId==game_id].iloc[0, [0, 5, 6]] # pull the ID (col 0), home team (col 5), visitng team (col 6)\n",
    "    filepath = f'./games/{game_data.iloc[0]}_{game_data.iloc[1]}_{game_data.iloc[2]}'\n",
    "\n",
    "    # Create a directory for the game if none exists\n",
    "    if not os.path.exists(filepath):\n",
    "        os.makedirs(filepath)\n",
    "\n",
    "    # Sort and organize the data\n",
    "    game_data_organized = organize_game_data(load_game_data(tracking_file, plays_file, game_id))\n",
    "    sorted_game_data_organized = sorted(game_data_organized.items(), key=lambda x: x[0])\n",
    "\n",
    "    # Using ProcessPoolExecutor to parallelize the loop\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        futures = [executor.submit(euclidean_distance_per_play, play, f'{filepath}/{key}') for key, play in sorted_game_data_organized]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tackle_percentage_contribution_per_play(frame_dict:dict, filepath:str, weights:pd.DataFrame=None, x_step:int=1, y_step:int=1): \n",
    "    \"\"\"\n",
    "    This iterates through the frames in any given play and calculates the tackle percentage contribution of each player\n",
    "    TODO: FIX THE CACULATION OF THE WEIGHTS\n",
    "    \n",
    "    Params: \n",
    "    - squares (pd.DataFrame): a dataframe with columns ['square_x', 'square_y', 'closest_player_id'].\n",
    "    - weights (pd.DataFrame): \n",
    "    - x_step (int): the x-side of the voronoi bins when caling the assign_squres_to_players method\n",
    "    - y_step (int): the y-side of the voronoi bins when caling the assign_squres_to_players method\n",
    "\n",
    "    Returns: \n",
    "    - dictionary with keys of nflId and value of the tackle percentage contribution for that play\n",
    "    \"\"\"\n",
    "    # empty dict, one indexed by player, the other indexed by frame\n",
    "    total_tpc = {}\n",
    "    tpc_per_frame = {}\n",
    "\n",
    "    # sort the frames\n",
    "    frame_dict_sorted = sorted(frame_dict.items(), key=lambda x: x[0])\n",
    "    # iterate through the frames of the play\n",
    "    for key, frame in frame_dict_sorted: \n",
    "\n",
    "        # get protected areas, append to both dictionaries\n",
    "        frame_tpc = tackle_percentage_contribution_per_frame(frame, weights, x_step, y_step)\n",
    "        tpc_per_frame[key] = frame_tpc\n",
    "\n",
    "        # append to the overall dict for the play\n",
    "        for player, contribution in frame_tpc.items():\n",
    "            if player in total_tpc.keys(): \n",
    "                total_tpc[player] += contribution\n",
    "            else: \n",
    "                total_tpc[player] = contribution\n",
    "    \n",
    "    # normalize every player's contribution such that it sums to 1\n",
    "    total_protected_area = sum(total_tpc.values())\n",
    "    for key, value in total_tpc.items():\n",
    "        total_tpc[key] = value / total_protected_area\n",
    "\n",
    "    # Convert the dictionary with the frame data to a DataFrame to cache\n",
    "    # The keys of the outer dict become the index, and the inner dicts' keys become the column names\n",
    "    tpc_per_frame_df = pd.DataFrame.from_dict(tpc_per_frame, orient='index')\n",
    "\n",
    "    # Save to CSV, with the index to make future multiplication easier\n",
    "    tpc_per_frame_df.to_csv(f'{filepath}/tpc_per_frame.csv', index=True)\n",
    "\n",
    "    # cast everything to strings from int64 (otherwise cannot store in JSON)\n",
    "    total_tpc_converted = {str(key): value for key, value in total_tpc.items()}\n",
    "\n",
    "    # cache this result as a JSON for each play\n",
    "    json.dump(total_tpc_converted, open(filepath+'/tpc.json', 'w'))\n",
    "\n",
    "    # create an animation\n",
    "    create_animation(frame_dict=frame_dict, tpc_per_frame=tpc_per_frame, play_filepath=filepath, x_step=x_step, y_step=y_step)\n",
    "\n",
    "    return total_tpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tackle_percentage_contribution_per_game(game_data_organized:dict, x_step:int=1, y_step:int=1): \n",
    "    \"\"\"\n",
    "    Iterate through all plays in the game and sum the defensive contribution of each player\n",
    "    \"\"\"\n",
    "    game_tpc = {}\n",
    "    # sort the plays in the game by the order they happened\n",
    "    sorted_game_data_organized = sorted(game_data_organized.items(), key=lambda x: x[1])\n",
    "    for key, play in sorted_game_data_organized: \n",
    "        print(key)  # for debugging purposes\n",
    "        play_tpc = tackle_percentage_contribution_per_play(play)\n",
    "        # append to the overall dict for the play\n",
    "        for player, contribution in play_tpc.items():\n",
    "            if player in game_tpc.keys(): \n",
    "                game_tpc[player] += contribution\n",
    "            else: \n",
    "                game_tpc[player] = contribution\n",
    "\n",
    "    return game_tpc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_game(game_id:str, \n",
    "                 tracking_file:str, \n",
    "                 x_step:int=1, \n",
    "                 y_step:int=1,\n",
    "                 plays_file:str='./data/plays.csv', \n",
    "                 players_file:str='./data/players.csv', \n",
    "                 game_file:str='./data/games.csv'):\n",
    "    \"\"\" \n",
    "    Analyze a game by creating a directory to store the results of each play and the relevant animation, and a file of overall TPC\n",
    "    \"\"\"\n",
    "    games = pd.read_csv(game_file)\n",
    "    game_data = games[games.gameId==game_id].iloc[0, [0, 5, 6]] # pull the date (col 0), home team (col 5), visitng team (col 6)\n",
    "    filepath = f'./games/{game_data.iloc[0]}_{game_data.iloc[1]}_{game_data.iloc[2]}'\n",
    "\n",
    "    # make a directory for the game if none exists\n",
    "    if not os.path.exists(filepath): \n",
    "        os.makedirs(filepath)\n",
    "\n",
    "    # organize the dta from the relevant game\n",
    "    game_data = load_game_data(tracking_file, plays_file, game_id)\n",
    "    game_data_organized = organize_game_data(game_data)\n",
    "    \n",
    "    # sort the plays in the game by the order they happened\n",
    "    game_tpc = {}\n",
    "    sorted_game_data_organized = sorted(game_data_organized.items(), key=lambda x: x[0])\n",
    "\n",
    "    # iterate through the plays\n",
    "    for key, play in sorted_game_data_organized: \n",
    "\n",
    "        print(key)  #  for debugging purposes\n",
    "        plt.close('all')  # close all open plots\n",
    "\n",
    "        try: \n",
    "            # make a directory to store information from the play\n",
    "            play_filepath = filepath + f'/{key}'\n",
    "            if not os.path.exists(play_filepath): \n",
    "                os.makedirs(play_filepath)\n",
    "\n",
    "            # calculate the tackle_percentage_contribution (this also caches the result as a JSON and creates an animation)\n",
    "            play_tpc = tackle_percentage_contribution_per_play(frame_dict=play, filepath=play_filepath, x_step=x_step, y_step=y_step)\n",
    "\n",
    "            # append to the overall dict for the play\n",
    "            for player, contribution in play_tpc.items():\n",
    "                if player in game_tpc.keys(): \n",
    "                    game_tpc[player] += contribution\n",
    "                else: \n",
    "                    game_tpc[player] = contribution\n",
    "                    \n",
    "        except Exception as e: \n",
    "            print(key, e)\n",
    "            continue\n",
    "\n",
    "    \n",
    "    # convert game_tpc keys from int64 to string to store in JSON\n",
    "    game_tpc_converted = {str(key): value for key, value in game_tpc.items()}\n",
    "    # cache this result as a JSON for each game\n",
    "    json.dump(game_tpc_converted, open(filepath+'/game_tpc.json', 'w'))\n",
    "\n",
    "    return game_tpc\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_play(key, play, filepath, x_step, y_step):\n",
    "    \"\"\"\n",
    "    Function to analyze a single play. This function will be executed in parallel.\n",
    "    \"\"\"\n",
    "    print(key)  # For debugging purposes\n",
    "\n",
    "    # Define the play's file path\n",
    "    play_filepath = f'{filepath}/{key}'\n",
    "    if not os.path.exists(play_filepath):\n",
    "        os.makedirs(play_filepath)\n",
    "\n",
    "    try:\n",
    "        # Calculate the tackle_percentage_contribution\n",
    "        # Ensure that the tackle_percentage_contribution_per_play function is defined appropriately\n",
    "        play_tpc = tackle_percentage_contribution_per_play(frame_dict=play, filepath=play_filepath, x_step=x_step, y_step=y_step)\n",
    "\n",
    "        return {player: contribution for player, contribution in play_tpc.items()}\n",
    "    except Exception as e:\n",
    "        print(f'Error processing play {key}: {e}')\n",
    "        return {}\n",
    "\n",
    "def analyze_game(game_id, tracking_file, x_step=1, y_step=1, plays_file='./data/plays.csv', players_file='./data/players.csv', game_file='./data/games.csv'):\n",
    "    \n",
    "    games = pd.read_csv(game_file)\n",
    "    game_data = games[games.gameId==game_id].iloc[0, [0, 5, 6]] # pull the date (col 0), home team (col 5), visitng team (col 6)\n",
    "    filepath = f'./games/{game_data.iloc[0]}_{game_data.iloc[1]}_{game_data.iloc[2]}'\n",
    "\n",
    "    # Create a directory for the game if none exists\n",
    "    if not os.path.exists(filepath):\n",
    "        os.makedirs(filepath)\n",
    "\n",
    "    # Sort and organize the data\n",
    "    game_data_organized = organize_game_data(load_game_data(tracking_file, plays_file, game_id))\n",
    "    sorted_game_data_organized = sorted(game_data_organized.items(), key=lambda x: x[0])\n",
    "\n",
    "    # Dictionary to store the overall tackle_percentage_contribution\n",
    "    game_tpc = {}\n",
    "\n",
    "    # Using ProcessPoolExecutor to parallelize the loop\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        futures = [executor.submit(analyze_play, key, play, filepath, x_step, y_step) for key, play in sorted_game_data_organized]\n",
    "\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            play_tpc = future.result()\n",
    "            for player, contribution in play_tpc.items():\n",
    "                game_tpc[player] = game_tpc.get(player, 0) + contribution\n",
    "\n",
    "    # Convert game_tpc keys from int64 to string to store in JSON\n",
    "    game_tpc_converted = {str(key): value for key, value in game_tpc.items()}\n",
    "    # Cache this result as a JSON for each game\n",
    "    json.dump(game_tpc_converted, open(filepath + '/game_tpc.json', 'w'))\n",
    "\n",
    "    return game_tpc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_animation(frame_dict: dict, tpc_per_frame: dict, play_filepath:str, x_min=0, x_max=120, y_min=0, y_max=53.3, x_step=1, y_step=1):\n",
    "    \"\"\"\n",
    "    Creates an animation of bucketed Voronoi spaces for different frames.\n",
    "\n",
    "    Parameters:\n",
    "    - frame_dict: Dictionary of DataFrames indexed by frame, each containing ['player_id', 'x', 'y'].\n",
    "    - tpc_per_frame (dict): returned from the tackle_percentage_contribution_per_play method that labels the contribution of each defensive player per play, each key is the frame\n",
    "    - play_filepath (str): the filepath used to save the animation \n",
    "    - min_x (float): the min x value in the graph (long side of football field, 0-120)\n",
    "    - max_x (float): the max x\n",
    "    - min_y (float): the min y value in the graph (short axis of football field, 0-53.3)\n",
    "    - max_y (float): the max y\n",
    "    - frame (int): the frame in question, useful for locating the file\n",
    "    \n",
    "    Returns:\n",
    "    - None\n",
    "\n",
    "    \"\"\"\n",
    "    # assign a color map for all players in the play, based on which players were active in the first frame\n",
    "    color_map = generate_color_map(frame_dict[sorted(frame_dict.keys())[0]].nflId) # from the first frame, pull all active players\n",
    "\n",
    "    # open plots were taking too much memory\n",
    "    plt.close('all')\n",
    "\n",
    "    # Function to draw a single frame for the animation\n",
    "    def draw_frame(frame_number):\n",
    "        \n",
    "        # Process the frame data to get the assignments\n",
    "        player_assignments = assign_squares_to_players(frame_dict[frame_number], x_min, x_max, y_min, y_max, x_step, y_step)\n",
    "        ball_carrier = frame_dict[frame_number].ballCarrierId.iloc[0]\n",
    "\n",
    "        nonlocal color_map\n",
    "        ax.clear()\n",
    "        ax.set_xlim(x_min, x_max)\n",
    "        ax.set_ylim(y_min, y_max)\n",
    "\n",
    "        # Create a list to hold all the rectangles\n",
    "        rectangles = []\n",
    "\n",
    "        # Create a list to hold the colors of each rectangle\n",
    "        rectangle_colors = []\n",
    "\n",
    "        for _, row in player_assignments.iterrows():\n",
    "\n",
    "            # plot the colors based on the closest player\n",
    "            player_id = row['closest_player_id']\n",
    "            square_color = color_map.get(player_id, 'grey')\n",
    "            rect = patches.Rectangle((row['square_x'] - 0.5, row['square_y'] - 0.5), 1, 1)\n",
    "            rectangles.append(rect)\n",
    "            rectangle_colors.append(square_color)\n",
    "\n",
    "        # Add labels at centroids\n",
    "        player_positions = zip(frame_dict[frame_number].nflId, frame_dict[frame_number].is_offense, frame_dict[frame_number].x, frame_dict[frame_number].y)\n",
    "        for player_id, is_offense, x, y in player_positions:\n",
    "\n",
    "            # Get tackle percentage contribution, default 0 for offense\n",
    "            tpc = tpc_per_frame[frame_number].get(player_id, 0) \n",
    "\n",
    "            # label the offensive players, red=ball carrier, black=offense, white=defense\n",
    "            if player_id == ball_carrier: \n",
    "                dot_color='red'\n",
    "            elif is_offense: \n",
    "                dot_color='black'\n",
    "            else: \n",
    "                dot_color='white'\n",
    "\n",
    "            # plot the dot for every player and their TPC\n",
    "            ax.plot(x, y, marker='o', markersize=5, markerfacecolor=dot_color)\n",
    "            ax.text(x, y, f'{player_id}: {tpc}', ha='center', va='center', fontsize=9)\n",
    "        # Create a PatchCollection and add it to the axis\n",
    "        pc = PatchCollection(rectangles, facecolor=rectangle_colors, edgecolor=None)\n",
    "        ax.add_collection(pc)\n",
    "\n",
    "        # Additional plot settings\n",
    "        ax.set_xlabel('Yards (X-axis)')\n",
    "        ax.set_ylabel('Yards (Y-axis)')\n",
    "        ax.set_title(f'Bucketed Voronoi Areas (ball carrier: {ball_carrier})')\n",
    "\n",
    "    # Create figure and axis for the animation\n",
    "    fig, ax = plt.subplots(figsize=(24, 12))\n",
    "\n",
    "    # Create the animation\n",
    "    anim = FuncAnimation(fig, draw_frame, frames=sorted(frame_dict.keys()), interval=200, repeat=False)\n",
    "\n",
    "    # To save the animation, uncomment the line below and specify the filename and writer\n",
    "    anim.save(play_filepath + f'/voronoi_visualizer.mp4', writer='ffmpeg')\n",
    "\n",
    "    # plt.show()\n",
    "    # return anim\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "week_1_tracking_file = './data/tracking_week_1.csv'\n",
    "plays_file = './data/plays.csv'\n",
    "game_data = load_game_data(week_1_tracking_file, plays_file, 2022090800)\n",
    "game_data_organized = organize_game_data(game_data)\n",
    "print(\"Number of plays: \", len(game_data_organized.keys()))\n",
    "\n",
    "# format of the organized data: \n",
    "test_frame = game_data_organized[56][7]\n",
    "test_frame.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# types of events in any given game\n",
    "for key, play in game_data_organized.items(): \n",
    "    events = []\n",
    "    for key2, value in play.items(): \n",
    "        events += [item for item in value.event]\n",
    "        print(set(events))\n",
    "set(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# voronoi tesselation\n",
    "points = np.column_stack([test_frame['x'].to_numpy(), test_frame['y'].to_numpy()])\n",
    "vor = Voronoi(points)\n",
    "fig = voronoi_plot_2d(vor)\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squares = assign_squares_to_players(test_frame, x_step=.5, y_step=.5)\n",
    "squares.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tackle_percentage_contribution_per_frame(test_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_map = generate_color_map(squares.closest_player_id)\n",
    "visualize_field(squares, color_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = game_data_organized[56]\n",
    "create_animation(test_dict, x_min=50, x_max=90, x_step=.3, y_step=.3, frame=56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_file = './data/games.csv'\n",
    "players_file = './data/players.csv'\n",
    "games = pd.read_csv(game_file)\n",
    "players = pd.read_csv(players_file)\n",
    "\n",
    "game_tpc_file = open('./games/2022090800_LA_BUF/game_tpc.json')\n",
    "game_tpc = json.load(game_tpc_file)\n",
    "sorted_game_tpc = sorted(game_tpc.items(), key=lambda x: x[1], reverse=True)\n",
    "labeled_dict = {}\n",
    "\n",
    "for id, score in sorted_game_tpc: \n",
    "    key = players[players.nflId==int(id)].iloc[0].displayName\n",
    "    labeled_dict[key] = score\n",
    "json.dump(labeled_dict, open('./games/2022090800_LA_BUF/labeled_game_tpc.json', 'w'))\n",
    "\n",
    "\n",
    "\n",
    "for player, score in sorted_game_tpc: \n",
    "    jugador = players[players.nflId==int(player)].iloc[0]\n",
    "    print(jugador.displayName, jugador.position, 'TPC over game: ', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take 1: TPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "week_1_tracking_file = './data/tracking_week_1.csv'\n",
    "plays_file = './data/plays.csv'\n",
    "game_data = load_game_data(week_1_tracking_file, plays_file, 2022090800)\n",
    "game_data_organized = organize_game_data(game_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_tpc = tackle_percentage_contribution_per_game(game_data_organized=game_data_organized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_file = './data/games.csv'\n",
    "players_file = './data/players.csv'\n",
    "games = pd.read_csv(game_file)\n",
    "players = pd.read_csv(players_file)\n",
    "print(games[games.gameId==2022090800])\n",
    "sorted_game_tpc = sorted(game_tpc.items(), key=lambda x: x[1], reverse=True)\n",
    "for key, value in sorted_game_tpc: \n",
    "    player = players[players.nflId==key].iloc[0]\n",
    "    print(player.displayName, \"TPC over game: \", value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take 2: Parallelized code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gameId</th>\n",
       "      <th>season</th>\n",
       "      <th>week</th>\n",
       "      <th>gameDate</th>\n",
       "      <th>gameTimeEastern</th>\n",
       "      <th>homeTeamAbbr</th>\n",
       "      <th>visitorTeamAbbr</th>\n",
       "      <th>homeFinalScore</th>\n",
       "      <th>visitorFinalScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022090800</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>09/08/2022</td>\n",
       "      <td>20:20:00</td>\n",
       "      <td>LA</td>\n",
       "      <td>BUF</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022091100</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>09/11/2022</td>\n",
       "      <td>13:00:00</td>\n",
       "      <td>ATL</td>\n",
       "      <td>NO</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022091101</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>09/11/2022</td>\n",
       "      <td>13:00:00</td>\n",
       "      <td>CAR</td>\n",
       "      <td>CLE</td>\n",
       "      <td>24</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022091102</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>09/11/2022</td>\n",
       "      <td>13:00:00</td>\n",
       "      <td>CHI</td>\n",
       "      <td>SF</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022091103</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>09/11/2022</td>\n",
       "      <td>13:00:00</td>\n",
       "      <td>CIN</td>\n",
       "      <td>PIT</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022091104</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>09/11/2022</td>\n",
       "      <td>13:00:00</td>\n",
       "      <td>DET</td>\n",
       "      <td>PHI</td>\n",
       "      <td>35</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022091105</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>09/11/2022</td>\n",
       "      <td>13:00:00</td>\n",
       "      <td>HOU</td>\n",
       "      <td>IND</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2022091106</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>09/11/2022</td>\n",
       "      <td>13:00:00</td>\n",
       "      <td>MIA</td>\n",
       "      <td>NE</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022091107</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>09/11/2022</td>\n",
       "      <td>13:00:00</td>\n",
       "      <td>NYJ</td>\n",
       "      <td>BAL</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022091109</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>09/11/2022</td>\n",
       "      <td>13:00:00</td>\n",
       "      <td>WAS</td>\n",
       "      <td>JAX</td>\n",
       "      <td>28</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       gameId  season  week    gameDate gameTimeEastern homeTeamAbbr  \\\n",
       "0  2022090800    2022     1  09/08/2022        20:20:00           LA   \n",
       "1  2022091100    2022     1  09/11/2022        13:00:00          ATL   \n",
       "2  2022091101    2022     1  09/11/2022        13:00:00          CAR   \n",
       "3  2022091102    2022     1  09/11/2022        13:00:00          CHI   \n",
       "4  2022091103    2022     1  09/11/2022        13:00:00          CIN   \n",
       "5  2022091104    2022     1  09/11/2022        13:00:00          DET   \n",
       "6  2022091105    2022     1  09/11/2022        13:00:00          HOU   \n",
       "7  2022091106    2022     1  09/11/2022        13:00:00          MIA   \n",
       "8  2022091107    2022     1  09/11/2022        13:00:00          NYJ   \n",
       "9  2022091109    2022     1  09/11/2022        13:00:00          WAS   \n",
       "\n",
       "  visitorTeamAbbr  homeFinalScore  visitorFinalScore  \n",
       "0             BUF              10                 31  \n",
       "1              NO              26                 27  \n",
       "2             CLE              24                 26  \n",
       "3              SF              19                 10  \n",
       "4             PIT              20                 23  \n",
       "5             PHI              35                 38  \n",
       "6             IND              20                 20  \n",
       "7              NE              20                  7  \n",
       "8             BAL               9                 24  \n",
       "9             JAX              28                 22  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "games_file = './adata/games.csv'\n",
    "games = pd.read_csv(games_file)\n",
    "games.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plays_file = './data/games.csv'\n",
    "plays = pd.read_csv(plays_file)\n",
    "plays.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LA_BUF_20220908 = NFLUtils.analyze_game(game_id=2022090800, tracking_file='./data/tracking_week_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATL_NO_20220911 = NFLUtils.analyze_game(game_id=2022091100, tracking_file='./data/tracking_week_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158\n",
      "85\n",
      "109\n",
      "272\n",
      "296\n",
      "184\n",
      "251\n",
      "213\n",
      "361\n",
      "382\n",
      "417\n",
      "489\n",
      "521\n",
      "542\n",
      "620\n",
      "Error processing play 361: 44820\n",
      "641\n",
      "662\n",
      "748\n",
      "850\n",
      "993\n",
      "1077\n",
      "1101\n",
      "1516\n",
      "1720\n",
      "1744\n",
      "Error processing play 993: 44898\n",
      "1785\n",
      "1901\n",
      "1945\n",
      "1980\n",
      "Error processing play 1516: 46104\n",
      "2051\n",
      "2320\n",
      "2341\n",
      "2365\n",
      "Error processing play 1101: 44820\n",
      "2386\n",
      "Error processing play 2051: 46104\n",
      "2407\n",
      "2478\n",
      "2501\n",
      "Error processing play 2386: 46104\n",
      "2545\n",
      "Error processing play 2407: 44898\n",
      "2629\n",
      "Error processing play 2501: 44898\n",
      "2683\n",
      "2783\n",
      "2832\n",
      "2909\n",
      "2930\n",
      "Error processing play 2629: 44820\n",
      "2951\n",
      "3040\n",
      "3080\n",
      "3101\n",
      "3125\n",
      "3221\n",
      "Error processing play 3125: 44820\n",
      "3263\n",
      "Error processing play 3040: 44820\n",
      "3315\n",
      "3336\n",
      "3357\n",
      "3378\n",
      "Error processing play 3336: 44898\n",
      "3399\n",
      "3545\n",
      "3569\n",
      "3591\n",
      "Error processing play 3315: 46104\n",
      "3615\n",
      "3669\n",
      "3707\n",
      "3789\n",
      "3841\n",
      "3862\n",
      "3923\n",
      "Error processing play 3615: 46104\n",
      "3961\n",
      "Error processing play 3569: 46104\n",
      "4068\n",
      "4104\n",
      "4150\n",
      "Error processing play 3789: 46093\n"
     ]
    }
   ],
   "source": [
    "CAR_CLE_20220911 = NFLUtils.analyze_game(game_id=2022091101, tracking_file='./data/tracking_week_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145\n",
      "343\n",
      "322\n",
      "364\n",
      "86\n",
      "531\n",
      "467\n",
      "574\n",
      "Error processing play 343: 47856\n",
      "698\n",
      "Error processing play 86: 47856\n",
      "756\n",
      "Error processing play 531: 53623\n",
      "800\n",
      "900\n",
      "921\n",
      "989\n",
      "1029\n",
      "Error processing play 921: 53623\n",
      "1050\n",
      "1162\n",
      "Error processing play 900: 53623\n",
      "1265\n",
      "1363\n",
      "Error processing play 989: 47856\n",
      "1406\n",
      "1472\n",
      "1493\n",
      "1517\n",
      "1588\n",
      "1631\n",
      "Error processing play 1472: 46377\n",
      "1794\n",
      "1837\n",
      "Error processing play 1050: 47856\n",
      "1869\n",
      "1954\n",
      "Error processing play 1588: 46377\n",
      "2065\n",
      "Error processing play 1794: 53646\n",
      "2132\n",
      "2238\n",
      "2281\n",
      "2352\n",
      "2394\n",
      "2415\n",
      "Error processing play 2394: 46377\n",
      "2511\n",
      "2532\n",
      "Error processing play 2352: 46377\n",
      "2556\n",
      "2618\n",
      "2717\n",
      "2738\n",
      "Error processing play 2511: 47856\n",
      "2759\n",
      "Error processing play 2618: 47856\n",
      "2783\n",
      "2945\n",
      "Error processing play 2556: 47856\n",
      "3022\n",
      "3043\n",
      "3336\n",
      "3381\n",
      "3428\n",
      "Error processing play 2783: 46377\n",
      "3470\n",
      "3502\n",
      "Error processing play 3502: 53646\n",
      "3628\n",
      "3695\n",
      "Error processing play 2738: 47819\n",
      "3783\n",
      "3859\n",
      "3943\n",
      "3981\n",
      "4019\n",
      "Error processing play 3943: 47856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rosetta error: ThreadContext::resume failed 4\n"
     ]
    },
    {
     "ename": "BrokenProcessPool",
     "evalue": "A process in the process pool was terminated abruptly while the future was running or pending.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBrokenProcessPool\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/arhamhabib/GitHub/nfl-big-data-bowl-2024/nfl_big_data_bowl.ipynb Cell 36\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/arhamhabib/GitHub/nfl-big-data-bowl-2024/nfl_big_data_bowl.ipynb#X53sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m CHI_SF_20220911 \u001b[39m=\u001b[39m NFLUtils\u001b[39m.\u001b[39;49manalyze_game(game_id\u001b[39m=\u001b[39;49m\u001b[39m2022091102\u001b[39;49m, tracking_file\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m./data/tracking_week_1.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/GitHub/nfl-big-data-bowl-2024/utils.py:338\u001b[0m, in \u001b[0;36manalyze_game\u001b[0;34m(game_id, tracking_file, x_step, y_step, plays_file, players_file, game_file)\u001b[0m\n\u001b[1;32m    335\u001b[0m futures \u001b[39m=\u001b[39m [executor\u001b[39m.\u001b[39msubmit(analyze_play, key, play, filepath, x_step, y_step) \u001b[39mfor\u001b[39;00m key, play \u001b[39min\u001b[39;00m sorted_game_data_organized]\n\u001b[1;32m    337\u001b[0m \u001b[39mfor\u001b[39;00m future \u001b[39min\u001b[39;00m as_completed(futures):\n\u001b[0;32m--> 338\u001b[0m     play_tpc \u001b[39m=\u001b[39m future\u001b[39m.\u001b[39;49mresult()\n\u001b[1;32m    339\u001b[0m     \u001b[39mfor\u001b[39;00m player, contribution \u001b[39min\u001b[39;00m play_tpc\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    340\u001b[0m         game_tpc[player] \u001b[39m=\u001b[39m game_tpc\u001b[39m.\u001b[39mget(player, \u001b[39m0\u001b[39m) \u001b[39m+\u001b[39m contribution\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py:439\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    438\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 439\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[1;32m    443\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py:391\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    390\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 391\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    392\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    393\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    394\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mBrokenProcessPool\u001b[0m: A process in the process pool was terminated abruptly while the future was running or pending."
     ]
    }
   ],
   "source": [
    "CHI_SF_20220911 = NFLUtils.analyze_game(game_id=2022091102, tracking_file='./data/tracking_week_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n",
      "295\n",
      "319\n",
      "364\n",
      "274\n",
      "253\n",
      "388\n",
      "340\n",
      "Error processing play 388: 44860\n",
      "520\n",
      "611\n",
      "632\n",
      "719\n",
      "743\n",
      "Error processing play 743: 53453\n",
      "764\n",
      "881\n",
      "Error processing play 764: 53453\n",
      "902\n",
      "955\n",
      "1037\n",
      "Error processing play 881: 44860\n",
      "1105\n",
      "1126\n",
      "1150\n",
      "1171\n",
      "1228\n",
      "1315\n",
      "Error processing play 1228: 52457\n",
      "1336\n",
      "1363\n",
      "1384\n",
      "1493\n",
      "1565\n",
      "1589\n",
      "Error processing play 1384: 44860\n",
      "1610\n",
      "1648\n",
      "Error processing play 1610: 44860\n",
      "1700\n",
      "Error processing play 1589: 44860\n",
      "1926\n",
      "1947\n",
      "2037\n",
      "Error processing play 1363: 44860\n",
      "2058\n",
      "2201\n",
      "2222\n",
      "2291\n",
      "Error processing play 2201: 44860\n",
      "2315\n",
      "2483\n",
      "2511\n",
      "Error processing play 2511: 53453\n",
      "2569\n",
      "2611\n",
      "2670\n",
      "2719\n",
      "2780\n",
      "Error processing play 2483: 53453\n",
      "2907\n",
      "2931\n",
      "Error processing play 2037: 53453\n",
      "2955\n",
      "2976\n",
      "3011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rosetta error: ThreadContext::resume failed 268435459\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBrokenProcessPool\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/GitHub/nfl-big-data-bowl-2024/utils.py:338\u001b[0m, in \u001b[0;36manalyze_game\u001b[0;34m(game_id, tracking_file, x_step, y_step, plays_file, players_file, game_file)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[39mfor\u001b[39;00m future \u001b[39min\u001b[39;00m as_completed(futures):\n\u001b[0;32m--> 338\u001b[0m     play_tpc \u001b[39m=\u001b[39m future\u001b[39m.\u001b[39;49mresult()\n\u001b[1;32m    339\u001b[0m     \u001b[39mfor\u001b[39;00m player, contribution \u001b[39min\u001b[39;00m play_tpc\u001b[39m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py:439\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 439\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py:391\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 391\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    392\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    393\u001b[0m     \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n",
      "\u001b[0;31mBrokenProcessPool\u001b[0m: A process in the process pool was terminated abruptly while the future was running or pending.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/arhamhabib/GitHub/nfl-big-data-bowl-2024/nfl_big_data_bowl.ipynb Cell 37\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/arhamhabib/GitHub/nfl-big-data-bowl-2024/nfl_big_data_bowl.ipynb#X54sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m CIN_PIT_20220911 \u001b[39m=\u001b[39m NFLUtils\u001b[39m.\u001b[39;49manalyze_game(game_id\u001b[39m=\u001b[39;49m\u001b[39m2022091103\u001b[39;49m, tracking_file\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m./data/tracking_week_1.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/GitHub/nfl-big-data-bowl-2024/utils.py:340\u001b[0m, in \u001b[0;36manalyze_game\u001b[0;34m(game_id, tracking_file, x_step, y_step, plays_file, players_file, game_file)\u001b[0m\n\u001b[1;32m    338\u001b[0m         play_tpc \u001b[39m=\u001b[39m future\u001b[39m.\u001b[39mresult()\n\u001b[1;32m    339\u001b[0m         \u001b[39mfor\u001b[39;00m player, contribution \u001b[39min\u001b[39;00m play_tpc\u001b[39m.\u001b[39mitems():\n\u001b[0;32m--> 340\u001b[0m             game_tpc[player] \u001b[39m=\u001b[39m game_tpc\u001b[39m.\u001b[39mget(player, \u001b[39m0\u001b[39m) \u001b[39m+\u001b[39m contribution\n\u001b[1;32m    342\u001b[0m \u001b[39m# Convert game_tpc keys from int64 to string to store in JSON\u001b[39;00m\n\u001b[1;32m    343\u001b[0m game_tpc_converted \u001b[39m=\u001b[39m {\u001b[39mstr\u001b[39m(key): value \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m game_tpc\u001b[39m.\u001b[39mitems()}\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py:637\u001b[0m, in \u001b[0;36mExecutor.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__exit__\u001b[39m(\u001b[39mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[0;32m--> 637\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshutdown(wait\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    638\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/concurrent/futures/process.py:767\u001b[0m, in \u001b[0;36mProcessPoolExecutor.shutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_executor_manager_thread_wakeup\u001b[39m.\u001b[39mwakeup()\n\u001b[1;32m    766\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_executor_manager_thread \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m wait:\n\u001b[0;32m--> 767\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_executor_manager_thread\u001b[39m.\u001b[39;49mjoin()\n\u001b[1;32m    768\u001b[0m \u001b[39m# To reduce the risk of opening too many files, remove references to\u001b[39;00m\n\u001b[1;32m    769\u001b[0m \u001b[39m# objects that use file descriptors.\u001b[39;00m\n\u001b[1;32m    770\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_executor_manager_thread \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/threading.py:1060\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1057\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcannot join current thread\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1059\u001b[0m \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1060\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wait_for_tstate_lock()\n\u001b[1;32m   1061\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1062\u001b[0m     \u001b[39m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m     \u001b[39m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1064\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[39m=\u001b[39m\u001b[39mmax\u001b[39m(timeout, \u001b[39m0\u001b[39m))\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/threading.py:1080\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1077\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m   1079\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1080\u001b[0m     \u001b[39mif\u001b[39;00m lock\u001b[39m.\u001b[39;49macquire(block, timeout):\n\u001b[1;32m   1081\u001b[0m         lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m   1082\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "CIN_PIT_20220911 = NFLUtils.analyze_game(game_id=2022091103, tracking_file='./data/tracking_week_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gameId               2022090800\n",
      "season                     2022\n",
      "week                          1\n",
      "gameDate             09/08/2022\n",
      "gameTimeEastern        20:20:00\n",
      "homeTeamAbbr                 LA\n",
      "visitorTeamAbbr             BUF\n",
      "homeFinalScore               10\n",
      "visitorFinalScore            31\n",
      "Name: 0, dtype: object\n",
      "56\n",
      "101\n",
      "167\n",
      "122\n",
      "146\n",
      "191\n",
      "212\n",
      "299\n",
      "343\n",
      "393\n",
      "414\n",
      "Error processing play 191: 52494\n",
      "486\n",
      "Error processing play 299: 47853\n",
      "529\n",
      "569\n",
      "593\n",
      "Error processing play 393: 47853\n",
      "617\n",
      "646\n",
      "692\n",
      "775\n",
      "818\n",
      "933\n",
      "1030\n",
      "1102\n",
      "1187\n",
      "1230\n",
      "1254\n",
      "1334\n",
      "Error processing play 1102: 52494\n",
      "1358\n",
      "1385\n",
      "1406\n",
      "1712\n",
      "Error processing play 1187: 47853\n",
      "1736\n",
      "1836\n",
      "Error processing play 1358: 44881\n",
      "1946\n",
      "1967\n",
      "2043\n",
      "2072\n",
      "2163\n",
      "2184\n",
      "2208\n",
      "2336\n",
      "2360\n",
      "2485\n",
      "2506\n",
      "2527\n",
      "2551\n",
      "2572\n",
      "2599\n",
      "2688\n",
      "2815\n",
      "2860\n",
      "2884\n",
      "2934\n",
      "Error processing play 2506: 52494\n",
      "3121\n",
      "3145\n",
      "3166\n",
      "Error processing play 2551: 52494\n",
      "3190\n",
      "3283\n",
      "Error processing play 3121: 43399\n",
      "3341\n",
      "3362\n",
      "3383\n",
      "3407\n",
      "3431\n",
      "Error processing play 3283: 47857\n",
      "3489\n",
      "3513\n",
      "Error processing play 3145: 47853\n",
      "3576\n",
      "3636\n",
      "gameId               2022091100\n",
      "season                     2022\n",
      "week                          1\n",
      "gameDate             09/11/2022\n",
      "gameTimeEastern        13:00:00\n",
      "homeTeamAbbr                ATL\n",
      "visitorTeamAbbr              NO\n",
      "homeFinalScore               26\n",
      "visitorFinalScore            27\n",
      "Name: 1, dtype: object\n",
      "145\n",
      "78\n",
      "121\n",
      "395\n",
      "166\n",
      "301\n",
      "458\n",
      "501\n",
      "522\n",
      "741\n",
      "762\n",
      "783\n",
      "Error processing play 762: 37101\n",
      "807\n",
      "870\n",
      "Error processing play 741: 37101\n",
      "914\n",
      "935\n",
      "956\n",
      "996\n",
      "Error processing play 914: 39975\n",
      "1046\n",
      "1067\n",
      "1170\n",
      "1260\n",
      "1303\n",
      "1335\n",
      "Error processing play 1170: 44879\n",
      "1359\n",
      "1413\n",
      "1434\n",
      "1552\n",
      "Error processing play 1303: 39975\n",
      "1651\n",
      "1672\n",
      "1769\n",
      "1887\n",
      "1928\n",
      "2048\n",
      "2069\n",
      "2090\n",
      "Error processing play 1887: 54473\n",
      "2135\n",
      "2159\n",
      "2183\n",
      "2245\n",
      "2332\n",
      "2353\n",
      "Error processing play 2183: 37101\n",
      "2491\n",
      "2595\n",
      "2616\n",
      "2720\n",
      "2741\n",
      "Error processing play 2353: 39975\n",
      "2809\n",
      "Error processing play 2069: 44879\n",
      "2878\n",
      "2899\n",
      "2960\n",
      "2984\n",
      "Error processing play 2899: 53612\n",
      "3148\n",
      "Error processing play 2984: 39975\n",
      "3177\n",
      "3289\n",
      "Error processing play 2491: 44879\n",
      "3310\n",
      "Error processing play 2809: 39975\n",
      "3334\n",
      "3355\n",
      "3379\n",
      "3475\n",
      "Error processing play 2741: 37101\n",
      "3526\n",
      "3554\n",
      "3578\n",
      "3647\n",
      "3757\n",
      "3778\n",
      "3888\n",
      "4032\n",
      "4102\n",
      "4266\n",
      "Error processing play 3379: 39975\n",
      "4307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rosetta error: thread_suspend failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gameId               2022091101\n",
      "season                     2022\n",
      "week                          1\n",
      "gameDate             09/11/2022\n",
      "gameTimeEastern        13:00:00\n",
      "homeTeamAbbr                CAR\n",
      "visitorTeamAbbr             CLE\n",
      "homeFinalScore               24\n",
      "visitorFinalScore            26\n",
      "Name: 2, dtype: object\n",
      "213\n",
      "158\n",
      "184\n",
      "85\n",
      "109\n",
      "251\n",
      "296\n",
      "272\n",
      "361\n",
      "382\n",
      "417\n",
      "489\n",
      "521\n",
      "542\n",
      "620\n",
      "Error processing play 361: 44820\n",
      "641\n",
      "662\n",
      "748\n",
      "850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rosetta error: ThreadContext::resume failed 268435459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gameId               2022091102\n",
      "season                     2022\n",
      "week                          1\n",
      "gameDate             09/11/2022\n",
      "gameTimeEastern        13:00:00\n",
      "homeTeamAbbr                CHI\n",
      "visitorTeamAbbr              SF\n",
      "homeFinalScore               19\n",
      "visitorFinalScore            10\n",
      "Name: 3, dtype: object\n",
      "364\n",
      "343\n",
      "86\n",
      "322\n",
      "145\n",
      "531\n",
      "574\n",
      "467\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "for label, row in games.iterrows(): \n",
    "    print(time.time - start_time)\n",
    "    try: \n",
    "        print(row)\n",
    "        game_id = row.gameId\n",
    "        week = row.week\n",
    "        results = NFLUtils.analyze_game(game_id=game_id, tracking_file=f'./data/tracking_week_{week}.csv')\n",
    "        time.sleep(30)  # doing this to not melt my processor overnight\n",
    "    except: \n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
